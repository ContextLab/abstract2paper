{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "abstract2paper.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNrqXQ+A2FWEgbxqf0pYHDm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "f43ab2c2955e460bb85345db36907aca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_9815cd8878e2499b9e5b07260bf63ce6",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_e84020541ddf415f9c2ed29095ce3e22",
              "IPY_MODEL_0349257905354cbab04f655bf41a3219"
            ]
          }
        },
        "9815cd8878e2499b9e5b07260bf63ce6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e84020541ddf415f9c2ed29095ce3e22": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_07138aff00f84cdf8ac9d825ae6baf96",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1347,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1347,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_019499e062d44c4ea44327d698b69295"
          }
        },
        "0349257905354cbab04f655bf41a3219": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_2935f220a3f84225812fe734fe5017ed",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1.35k/1.35k [00:00&lt;00:00, 1.68kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_e14eed39ccb14c60a90f183a19a8000c"
          }
        },
        "07138aff00f84cdf8ac9d825ae6baf96": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "019499e062d44c4ea44327d698b69295": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "2935f220a3f84225812fe734fe5017ed": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "e14eed39ccb14c60a90f183a19a8000c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "29987243b4ef436597c0345880dfc76d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_a95ecd3404c140bea98dd04103752052",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_741c528f4b8e4ad48b1000f527b1335f",
              "IPY_MODEL_40f9fe77f959498a9cc3cfa0880db779"
            ]
          }
        },
        "a95ecd3404c140bea98dd04103752052": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "741c528f4b8e4ad48b1000f527b1335f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_27d1a1595efc4495b66cee4613fd392b",
            "_dom_classes": [],
            "description": "Downloading:  86%",
            "_model_name": "FloatProgressModel",
            "bar_style": "",
            "max": 5312753599,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 4577303552,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_7b0e5365797c419eb26d8b9c17427957"
          }
        },
        "40f9fe77f959498a9cc3cfa0880db779": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_f7311d9585994521958e8a2a44b93531",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 4.58G/5.31G [01:49&lt;00:16, 44.9MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_7395ec9470d64b719ac2fa75099861c9"
          }
        },
        "27d1a1595efc4495b66cee4613fd392b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "7b0e5365797c419eb26d8b9c17427957": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f7311d9585994521958e8a2a44b93531": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "7395ec9470d64b719ac2fa75099861c9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ContextLab/abstract2paper/blob/main/resources/abstract2paper.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dAVD2y6e-iZO"
      },
      "source": [
        "# Welcome to *abstract2paper*!\n",
        "Author: [Jeremy R. Manning](http://www.context-lab.com/)\n",
        "\n",
        "## Step right up, step right up!\n",
        "<img src='https://media1.giphy.com/media/mL40PfXA394KA/giphy.gif' width='250px'>\n",
        "\n",
        "**Writing papers got you down?** Come on in, friend!  Give my good ole' Abstract2papers Cure-All a quick try!  Enter your abstract into the little doohicky here, and quicker'n you can blink your eyes<sup>1</sup>, a shiny new paper'll come right out for ya!  What are you waiting for?\n",
        "\n",
        "## How does it work, you ask?\n",
        "\n",
        "Really it's quite simple.  We put in a smidgen of [this](https://huggingface.co/transformers/model_doc/gpt_neo.html) a pinch of [that](https://www.tug.org/texlive/), plus a dab of our special [*secret ingredient*](https://www.youtube.com/watch?v=dQw4w9WgXcQ), and **poof!** that's how the sausage is made.\n",
        "\n",
        "## No really, how does it work?\n",
        "\n",
        "Ok, if you really want to know, all I'm doing here is using the [Hugging Face](https://huggingface.co/) [implementation](https://huggingface.co/transformers/model_doc/gpt_neo.html) of [GPT-Neo](https://github.com/EleutherAI/gpt-neo), which is itself a tweaked version of [GPT-3](https://arxiv.org/abs/2005.14165) that is pre-trained on the [Pile](https://pile.eleuther.ai/) dataset.\n",
        "\n",
        "The text you input is used as a prompt for GPT-Neo; to generate a document containing an additional *n* words, the model simply \"predicts\" the next *n* words that will come after the specified prompt.\n",
        "\n",
        "With a little help from some basic [LaTeX](https://www.latex-project.org/) templates (borrowed from [Overleaf](https://www.overleaf.com)), the document is formatted and compiled into a PDF.\n",
        "\n",
        "## Can I actually use this in real-world applications?\n",
        "\n",
        "<img src='https://media4.giphy.com/media/3o6ozoD1ByqYv7ARIk/giphy.gif' width='250px'>\n",
        "\n",
        "**Doubtful.**  Or at least, probably not...?  It certainly wouldn't be ethical to use this code to generate writing assignments, mass-produce papers or grant applications, etc.  Further, you'll likely find that the text produced using this approach includes stuff that's said in funny (often nonsensical) ways, follows problematic logic, incorporates biases from the training data, and so on.  Of lesser importance, but practical annoyance, you'll also encounter all sorts of formatting issues (although those might be easy to fix manually, and possibly even automatically with some clever tinkering).\n",
        "\n",
        "&nbsp;\n",
        "&nbsp;\n",
        "&nbsp;\n",
        "&nbsp;\n",
        "\n",
        "<sup>1</sup><small>This claim rests on the assumption that you blink *really* slowly.  Depending on how much text you're trying to generate (and how long your prompt is), your paper could take anywhere from a few minutes to several hours to fully congeal.</small>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vQ52hti0G13T"
      },
      "source": [
        "# Step 1: Setting up the environment\n",
        "\n",
        "We're going to use the super-convenient [Davos](https://github.com/ContextLab/davos.git) package to manage our dependencies.  We need to install it and import it in order to gain access to the `smuggle` keyword."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W_8EF8P93B0H",
        "outputId": "e508526c-7c15-4856-b6d1-d3b2f6902728"
      },
      "source": [
        "!pip install git+https://github.com/ContextLab/davos.git\n",
        "import davos"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting git+https://github.com/ContextLab/davos.git\n",
            "  Cloning https://github.com/ContextLab/davos.git to /tmp/pip-req-build-8qj8fowq\n",
            "  Running command git clone -q https://github.com/ContextLab/davos.git /tmp/pip-req-build-8qj8fowq\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: davos\n",
            "  Building wheel for davos (PEP 517) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for davos: filename=davos-0.0.1-cp37-none-any.whl size=37733 sha256=7c9b2460f16de05849904876e4e011f5ff45bff5d8850cfa5ec07c79aa4f4780\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-8ccm_0i4/wheels/62/30/bc/79958ce75e105bdcf95c737091e62372429850960d6628e277\n",
            "Successfully built davos\n",
            "Installing collected packages: davos\n",
            "Successfully installed davos-0.0.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fOzbwY-WHVZg"
      },
      "source": [
        "Next, we'll install Hugging Face's [transformers](https://huggingface.co/transformers/) library and download (and load into memory) the pre-trained GPT-Neo model.  We'll also use a pretrained GPT-2 tokenizer for convenience.\n",
        "\n",
        "NB: When you have access to more RAM, you may want to replace `'EleutherAI/gpt-neo-1.3B'` with `'EleutherAI/gpt-neo-2.7B'` in the second two lines in the cell below.  That will load in a fancier (but larger) model-- with 2.7 billion parameters instead of a \"measly\" 1.3 billion parameters.\n",
        "\n",
        "There's a lot to download (roughly 6GB for the smaller model and 12.5GB for the larger model)-- it'll take a few minutes.  Now would be a good time to track down that coffee refill you've been postponing..."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 669,
          "referenced_widgets": [
            "f43ab2c2955e460bb85345db36907aca",
            "9815cd8878e2499b9e5b07260bf63ce6",
            "e84020541ddf415f9c2ed29095ce3e22",
            "0349257905354cbab04f655bf41a3219",
            "07138aff00f84cdf8ac9d825ae6baf96",
            "019499e062d44c4ea44327d698b69295",
            "2935f220a3f84225812fe734fe5017ed",
            "e14eed39ccb14c60a90f183a19a8000c",
            "29987243b4ef436597c0345880dfc76d",
            "a95ecd3404c140bea98dd04103752052",
            "741c528f4b8e4ad48b1000f527b1335f",
            "40f9fe77f959498a9cc3cfa0880db779",
            "27d1a1595efc4495b66cee4613fd392b",
            "7b0e5365797c419eb26d8b9c17427957",
            "f7311d9585994521958e8a2a44b93531",
            "7395ec9470d64b719ac2fa75099861c9"
          ]
        },
        "id": "sMaklzRv3QjF",
        "outputId": "840fb6e1-a78c-4c7d-feaf-43256219d2a1"
      },
      "source": [
        "from transformers smuggle GPTNeoForCausalLM, GPT2Tokenizer\n",
        "model = GPTNeoForCausalLM.from_pretrained(\"EleutherAI/gpt-neo-1.3B\")\n",
        "tokenizer = GPT2Tokenizer.from_pretrained(\"EleutherAI/gpt-neo-1.3B\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/00/92/6153f4912b84ee1ab53ab45663d23e7cf3704161cb5ef18b0c07e207cef2/transformers-4.7.0-py3-none-any.whl (2.5MB)\n",
            "\u001b[K     |████████████████████████████████| 2.5MB 4.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers) (4.5.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/75/ee/67241dc87f266093c533a2d4d3d69438e57d7a90abb216fa076e7d475d4a/sacremoses-0.0.45-py3-none-any.whl (895kB)\n",
            "\u001b[K     |████████████████████████████████| 901kB 29.3MB/s \n",
            "\u001b[?25hCollecting huggingface-hub==0.0.8\n",
            "  Downloading https://files.pythonhosted.org/packages/a1/88/7b1e45720ecf59c6c6737ff332f41c955963090a18e72acbcbeac6b25e86/huggingface_hub-0.0.8-py3-none-any.whl\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from transformers) (3.13)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n",
            "Collecting tokenizers<0.11,>=0.10.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d4/e2/df3543e8ffdab68f5acc73f613de9c2b155ac47f162e725dcac87c521c11/tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3MB)\n",
            "\u001b[K     |████████████████████████████████| 3.3MB 33.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (20.9)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.4.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.7.4.3)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.5.30)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Installing collected packages: sacremoses, huggingface-hub, tokenizers, transformers\n",
            "Successfully installed huggingface-hub-0.0.8 sacremoses-0.0.45 tokenizers-0.10.3 transformers-4.7.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f43ab2c2955e460bb85345db36907aca",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=1347.0, style=ProgressStyle(description…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "29987243b4ef436597c0345880dfc76d",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=5312753599.0, style=ProgressStyle(descr…"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qwQr2ziLIUyG"
      },
      "source": [
        "# Now I'm only going to ask this once: we're going to need a little...*information* from you...\n",
        "<img src='https://64.media.tumblr.com/e3c8dea30fdf2e597ce79904e8da3271/tumblr_o2xhqwU0cK1qmob6ro2_500.gif' width=400px>\n",
        "\n",
        "You didn't think it was going to be *that* easy, did you?  Oh...you did?  Well if you want *us* to cooperate, we're going to need a little...information...from you first.  About your paper.  Please make this easy on all of us and don't try to lie.  The machine will know.  The machine *always* knows...\n",
        "\n",
        "Fill in the information below and you'll be well on your way to your auto-generated paper/story/grant application/speech/business plan.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "amOYPyewDLtE"
      },
      "source": [
        "# credit: https://www.gutenberg.org/files/98/98-h/98-h.htm\n",
        "title = 'An auto-generated tale of two (or more) cities:\\\\\\\\A story of the NLP revolution'\n",
        "authors = 'Charles Dickens'\n",
        "text = 'It was the best of times, it was the worst of times, it was the age of wisdom, it was the age of foolishness, ' \\\n",
        "       'it was the epoch of belief, it was the epoch of incredulity, it was the season of Light, it was the season of ' \\\n",
        "       'Darkness, it was the spring of hope, it was the winter of despair, we had everything before us, ' \\\n",
        "       'we had nothing before us, we were all going direct to Heaven, we were all going direct the other way—in ' \\\n",
        "       'short, the period was so far like the present period, that some of its noisiest authorities insisted on its ' \\\n",
        "       'being received, for good or for evil, in the superlative degree of comparison only. '\n",
        "length = 1000"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MiBDPVxLMQMT"
      },
      "source": [
        "The next cell is going to take a while to run.  While you're waiting, just think: it's still better than writing something on your own, isn't it?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7rfrKf764v51"
      },
      "source": [
        "ids = tokenizer(text, return_tensors='pt')['input_ids']\n",
        "tokens = model.generate(ids, do_sample=True, temperature=0.9, max_length=length)\n",
        "gen_text = tokenizer.batch_decode(tokens)[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fUfWHWA8ILSP"
      },
      "source": [
        "And finally, we'll get a tex-live installation going in our Colaboratory environment and download a template for generating the final document.  (First we need to remove the model and tokenizer from RAM so that Colaboratory doesn't hit its memory limit and crash.)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mk-ZZeDfM8SJ"
      },
      "source": [
        "# memory cleanup\n",
        "import gc, os\n",
        "del model, tokenizer  # you can comment out this line if you're not\n",
        "                      # running this on a memory-limited machine\n",
        "gc.collect()          # remove the (now unused) variables from memory\n",
        "\n",
        "# install tex-live\n",
        "!apt-get install texlive-latex-recommended\n",
        "\n",
        "# download template\n",
        "!git clone https://github.com/ContextLab/abstract2paper"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fgat6lZRCV1y"
      },
      "source": [
        "def texer(template, outfile='auto.tex', **kwargs):\n",
        "  with open(template, 'r') as f:\n",
        "    lines = f.readlines()\n",
        "\n",
        "  x = []\n",
        "  for line in lines:\n",
        "    for k, v in kwargs.items():\n",
        "      line = line.replace(f'<{k}>', str(v))\n",
        "    x.append(line.replace(' & ', ' \\& ').replace('%', '\\%'))\n",
        "  \n",
        "  try:\n",
        "    with open(outfile, 'w+') as f:\n",
        "      f.write('\\n'.join(x))\n",
        "  \n",
        "    os.system(f'pdflatex {outfile}')\n",
        "    os.system('rm *.log *.aux')\n",
        "\n",
        "  except:\n",
        "    pass\n",
        "\n",
        "  return '\\n'.join(x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OZPYsfDDQ-q2"
      },
      "source": [
        "Create a PDF containing your auto-generated document..."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "73tadb3xQD_t"
      },
      "source": [
        "source = texer(os.path.join('abstract2paper', 'resources', 'template.tex'), TITLE=title, AUTHOR=authors+'\\\\\\\\Augmented by GPT-Neo', GEN_TEXT=gen_text + '...')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XRzAVkyOHA0S"
      },
      "source": [
        "import pprint\n",
        "pprint.pprint(source, width=80)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GcKjadzEHoQb"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}